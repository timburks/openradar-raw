apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "32747071"
    labels:
        datastore_id: "5026202339246080"
data:
    classification: ""
    created: "2017-06-13T20:28:48.93409Z"
    description: "Currently, with the new feature of watchOS 4 allowing for realtime audio processing (via AVAudioInputNode), we have no way to keep the screen alive while we have a tap installed on the AVAudioInputNode from the AVAudioEngine. This means we can only keep rendering updates from the received audio data for the duration the user has specified in their watches \"On Tap\" settings of either 15 or 75 seconds. We should be permitted to request additional time to keep the screen alive, similar to how the stock AudioRecorderController has the ability to keep the screen alive for the duration of the recording in order to provide realtime graphics rendering.\r\n\r\nDue to these limitations, this results in a poor user experience for users attempting to visually interact with incoming audio data. We can, as an alternative, issue the user to go to their watch settings on the iPhone and set this \"On Tap\" duration to the longest possible setting, however we also do not have a way to push the user there from the watch (a different issue)."
    email: Alex.Silvio.Muller@gmail.com
    modified: "2017-06-13T20:28:48.93437Z"
    number: "32747071"
    number_intvalue: 32747071
    originated: 06/13/2017
    parent_number: '&{NULL_VALUE}'
    product: watchOS
    product_version: 4.0 (15R5281F)
    reproducible: ""
    resolved: ""
    status: Open
    title: WatchOS 4 - Feature parity should exist between using AudioRecorderController and realtime audio analysis via AVAudioInputNode around keeping screen on
