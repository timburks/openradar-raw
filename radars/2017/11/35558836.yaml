apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "35558836"
    labels:
        datastore_id: "4964308337295360"
data:
    classification: Suggestion
    created: "2017-11-15T14:27:42.40366Z"
    description: "Area:\r\nAccessibility\r\n\r\nThe new screenshot capabilities in iOS 11 are wonderful, but they could be made much more useful for visually-impaired users if the system were to capture + embed the current VoiceOver state (label, traits, hint, frame, etc) in the screenshot image; that way, users could explore a screenshot long after taking it, and could also access that data in other apps. It would give visually-impaired users the same ability to capture the current state of their phone (for sharing or remembering or annotating or whatever other purpose) that sighted users have now.\r\n\r\nAs a bonus, this could also have a number of useful benefits for sighted users; for example, one could pull up a screenshot in a foreign language dictionary / translator app and easily translate embedded text, or one could tag / index screenshots based on their text for later retrieval, or social networking services could automatically detect + crop out the user interface portion of a screenshot and show just the content.\r\n\r\nThis would also provide an added incentive for developers to support VoiceOver, since now sighted users would have a reason to demand VoiceOver support too."
    email: mikelove@pleco.com
    modified: "2017-11-15T14:27:42.40392Z"
    number: "35558836"
    number_intvalue: 35558836
    originated: 11/15/17
    parent_number: '&{NULL_VALUE}'
    product: iOS + SDK
    product_version: ""
    reproducible: ""
    resolved: ""
    status: ""
    title: Screenshots should include embedded accessibility text
