apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "26919080"
    labels:
        datastore_id: "4990805919924224"
data:
    classification: ""
    created: "2016-06-21T15:46:25.31914Z"
    description: "Summary:\r\nThere are many homophones and near homophones which could greatly complicate extracting intent from spoken text. If developers were provided a way to express common terms in their app’s domain before recognition takes place, this challenge could be considerably lessened.\r\n\r\nThe most ideal API that I can think of would involve providing a dictionary `[String:String]` with International Phonetic Alphabet spellings mapped to the common terms . For an application concerned with music notes and pitches, a dictionary might contain\r\n\r\n``` swift\r\n\r\nlet letterDictionary: [String: String] = [\r\n    \"ə\" :  \"A\",\r\n    \"bi\" :  \"B\",\r\n    \"si\" :  \"C\",\r\n    \"di\" :  \"D\",\r\n    \"i\" :  \"E\",\r\n    \"ɛf\" :  \"F\",\r\n    \"ʤi\" :  \"G\"\r\n]\r\n```\r\n\r\nThis example is also an example of why we would want to allow dynamic alteration of this hint, possibly via delegation, since the same app would probably want to change the term associated with “si” to “si” in the context of solfeggio syllables (do re mi fa sol la si do)."
    email: GriotSpeak@gmail.com
    modified: "2016-06-21T15:46:35.58592Z"
    number: "26919080"
    number_intvalue: 26919080
    originated: "2016-06-21"
    parent_number: '&{NULL_VALUE}'
    product: ""
    product_version: ""
    reproducible: ""
    resolved: ""
    status: Open
    title: 'Xcode-beta (8S128d): SFSpeechRecognizer API to provide domain hints'
