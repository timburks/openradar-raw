apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "24070521"
    labels:
        datastore_id: "5021485877952512"
data:
    classification: UI/Usability Enhancement
    created: "2016-01-06T10:16:16.35739Z"
    description: "Modern applications, such as instant messaging and social networking apps, are heavily dependent of interacting with the system keyboard. Users have high expectations regarding being able to interact with the keyboard in a seamless way they generally do with built-in applications such as Messages and Notes. It is hard to offer basic features related to the keyboard when a handful of APIs are remained private to third-party developers.\r\n\r\nThe UIKeyboard APIs defined in UITextInputTraits and UIWindow haven't changed much since iOS 5. The UIKeyboard notifications' payloads are limited and hard to work with when more advanced logic is required. For example, on the iPad, detecting if the keyboard is anchored, or split, or simply not visible because an external keyboard is in use, it is barely impossible. There are a few fragile ways of assuming these states, based on the keyboard size and origin, but the state detection cannot be guaranteed and therefore, prone to bugs with any race condition or new OS version being released.\r\n\r\nTo help guaranteeing keyboard UI modes such as those, I propose the following enumeration to be added to the UITextInputTraits informal protocol:\r\n\r\ntypedef NS_ENUM(NSInteger, UIKeyboardMode) {\r\n    UIKeyboardModeDocked,                 // Default mode of the keyboard, fully visible\r\n    UIKeyboardModeUnDocked,               // When the keyboard is detached from the bottom of the screen (iPad only)\r\n    UIKeyboardModeSplit,                  // When the keyboard layout is split in half (iPad only)\r\n    UIKeyboardModeHidden,                 // When an external keyboard is detected, therefore the virtual keyboard is hidden from screen\r\n};\r\n\r\n\r\nA companion API to the previous proposition, is being able to detect the keyboard's origin and size, at any time and observe its changes. This would greatly help to improve any user experience related to the keyboard. For example, a feature such as making a text input follow the keyboard whenever it appears or disappears, or being able to drag down/up the keyboard with a simple panning gesture, may seem trivial to any user. Without the notion of the keyboard's frame, it is extremely hard to work around these user expectations.\r\n\r\nTherefore, I propose to add a new KVO compliant property to the UIKeyInput protocol:\r\n\r\n@property (nonatomic, readonly) CGRect keyboardFrame;\r\n\r\n\r\nFinally, as part of making the keyboard's user experience greater, I propose to add two new flags to the UITextInput protocol, for handling special text input's cursor states triggered by user gestures:\r\n\r\n@property (nonatomic, readonly) BOOL isTrackpadEnabled;       // YES if the keyboard track pad has been recognised.\r\n@property (nonatomic, readonly) BOOL isLoupeVisible;          // YES if the magnifying glass is visible.\r\n\r\nKnowing those 2 states would, for example, help skipping any text processing on a text input while the user freely moves the cursor."
    email: ignacio@slack-corp.com
    modified: "2016-01-14T08:36:14.82422Z"
    number: "24070521"
    number_intvalue: 24070521
    originated: Jan 6, 2016
    parent_number: '&{NULL_VALUE}'
    product: iOS
    product_version: "9.2"
    reproducible: Always
    resolved: No
    status: Duplicate of 9261950
    title: Allow better keyboard states detection
