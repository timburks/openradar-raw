apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "22873794"
    labels:
        datastore_id: "6701604203921408"
data:
    classification: ""
    created: "2015-09-27T23:36:20.44049Z"
    description: "Summary:\r\n-[AVAudioPlayerNode scheduleFile:atTime:completionHandler:] is documented as \"called after the file has completely played or the player is stopped\", but is called before the file has completely played.  There does not appear to be any way to determine whether the file has finished playing, even by polling.\r\n\r\nSteps to Reproduce:\r\n1. Install Xcode 7.\r\n2. Build and run the attached project.\r\n3. Observe the console output, which queues 10 brief sound files then logs the time and lastRenderTime for each file; it also polls the player state approximately each second.\r\n\r\nExpected Results:\r\nThe completion handler fires once at the end of playback of each file's playback.\r\n\r\nActual Results:\r\nThe first two completion handlers fire essentially right after one another; the remaining ones fire at later times, but audio continues even after the last completion handler has fired.\r\n\r\nTime continues to advance and the player doesn't stop itself when it's finished playing audio, so there's no way I can figure out how to query the player to figure out if it's finished.\r\n\r\n2015-09-27 19:24:21.193 AVAudioEngineCompletion[9946:369939] playing 0 <AVAudioTime 0x6080000a8280: 30642.368875 s 0 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:21.194 AVAudioEngineCompletion[9946:369939] playing 1 <AVAudioTime 0x6080000a7f80: 30642.368875 s 0 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:21.601 AVAudioEngineCompletion[9946:369939] playing 2 <AVAudioTime 0x6000000a60c0: 30642.777492 s 18020 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:22.101 AVAudioEngineCompletion[9946:369939] playing 3 <AVAudioTime 0x6080000a63c0: 30643.276721 s 40036 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:22.270 AVAudioEngineCompletion[9946:369853] 1 - <AVAudioTime 0x6000000a2d00: 30643.439261 s 47204 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:22.600 AVAudioEngineCompletion[9946:369939] playing 4 <AVAudioTime 0x6080000a63c0: 30643.775950 s 62052 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:23.099 AVAudioEngineCompletion[9946:369939] playing 5 <AVAudioTime 0x6080000a63c0: 30644.275179 s 84068 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:23.374 AVAudioEngineCompletion[9946:369853] 2 - <AVAudioTime 0x6080000a63c0: 30644.542209 s 95844 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:23.587 AVAudioEngineCompletion[9946:369939] playing 6 <AVAudioTime 0x6080000a63c0: 30644.762799 s 105572 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:24.086 AVAudioEngineCompletion[9946:369939] playing 7 <AVAudioTime 0x6080000a63c0: 30645.262028 s 127588 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:24.180 AVAudioEngineCompletion[9946:369853] 3 - <AVAudioTime 0x6000000a57c0: 30645.354907 s 131684 fr (/44100 Hz) 1.000000 rs>\r\n2015-09-27 19:24:24.585 AVAudioEngineCompletion[9946:369939] playing 8 <AVAudioTime 0x6080000a63c0: 30645.761258 s 149604 fr (/44100 Hz) 1.000001 rs>\r\n2015-09-27 19:24:25.085 AVAudioEngineCompletion[9946:369939] playing 9 <AVAudioTime 0x6000000a5820: 30646.260487 s 171620 fr (/44100 Hz) 1.000001 rs>\r\n2015-09-27 19:24:25.579 AVAudioEngineCompletion[9946:369853] 4 - <AVAudioTime 0x6080000a63c0: 30646.748107 s 193124 fr (/44100 Hz) 1.000001 rs>\r\n2015-09-27 19:24:26.547 AVAudioEngineCompletion[9946:369853] 5 - <AVAudioTime 0x6080000a63c0: 30647.711735 s 235620 fr (/44100 Hz) 1.000001 rs>\r\n2015-09-27 19:24:27.180 AVAudioEngineCompletion[9946:369853] 6 - <AVAudioTime 0x6000000a1860: 30648.350284 s 263780 fr (/44100 Hz) 1.000000 rs>\r\n\r\nVersion:\r\nXcode Version 7.0 (7A218) / OS X 10.11 (15A282b)\r\n\r\nNotes:\r\nI am using AVAudioPlayerNode rather than a higher-level API to play a sound file because I need to control the output device.\r\n\r\nThe task of playing audio or even audio associated with video through a selected output device was trivial with QuickTime, but there is no direct analog to set an audio device in higher-level AVFoundation APIs (https://forums.developer.apple.com/message/59178).\r\n\r\nThe ability to route sound beyond the alert/system devices (or not even being given a choice between those two in some cases) seems to be being lost in OS X, without associated intelligent routing of sound (e.g., sending alarm sounds out the speaker while headphones are plugging in) that exists on iOS â€” it seems to be the worst of both worlds, requiring manual configuration and breaking old workflows without an adequate replacement.\r\n\r\nConfiguration:\r\nIdentical results are observed on OS X 10.10.5 and 10.11.\r\n\r\nAttachments:\r\n'AVAudioEngineCompletion.zip' was successfully uploaded.\r\n(http://sabi.net/temp/22873794/AVAudioEngineCompletion.zip)"
    email: nriley@gmail.com
    modified: "2015-09-27T23:36:20.4408Z"
    number: "22873794"
    number_intvalue: 22873794
    originated: 27-Sep-2015 07:35 PM
    parent_number: '&{NULL_VALUE}'
    product: OS X SDK
    product_version: ""
    reproducible: ""
    resolved: ""
    status: Open
    title: -[AVAudioPlayerNode scheduleFile:atTime:completionHandler:] doesn't invoke completion handler as documented; no way to figure out if file is finished playing
