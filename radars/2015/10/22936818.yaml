apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "22936818"
    labels:
        datastore_id: "6137846964420608"
data:
    classification: Feature (New)
    created: "2015-10-01T18:39:18.33392Z"
    description: "Summary:\r\nIt would be very useful to have a way of allocating memory when needed in compute shader tasks that don't have a predefined output size, e.g. the marching cubes algorithm (https://en.wikipedia.org/wiki/Marching_cubes), like cudaMalloc allows in CUDA.\r\n\r\nCurrently the workaround is to preallocate a big heap of memory and have the current thread on GPU increment an atomic int to know which chunk it can use. While this works, it requires a lot of memory (especially if you forecast a lot of chunks *could* be used) and sometimes garbage collection is needed (e.g. some chunks that were in use can now be deleted/reused).\r\n\r\nSteps to Reproduce:\r\nuse a compute shader that has a varying output size\r\n\r\nExpected Results:\r\ndon't need to worry about the size of the output buffer before the shader runs\r\n\r\nActual Results:\r\npreallocate a big heap of memory with CPU instructions"
    email: adgror@gmail.com
    modified: "2015-10-01T18:39:18.3342Z"
    number: "22936818"
    number_intvalue: 22936818
    originated: 01-Oct-2015
    parent_number: '&{NULL_VALUE}'
    product: iOS SDK
    product_version: ""
    reproducible: Always
    resolved: ""
    status: Open
    title: Allow memory allocation in shaders like cudaMalloc OR an "append" buffer
