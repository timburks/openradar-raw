apiVersion: openapi/v1alpha1
kind: Radar
metadata:
    name: "23234334"
    labels:
        datastore_id: "4940592853286912"
data:
    classification: Serious Bug
    created: "2015-10-23T13:05:47.76611Z"
    description: |-
        When running the following sample code, Core Image explicitly mentions in the logs that it refuses 32-bit floating point working format.
        This drastically reduces computation precision, and is a departure from what was possible to do in the last 5+ years.

        The header file explicitely mentions that 32-bit floating-point is supported on OS X:
        /* An NSNumber with a CIFormat value defining the pixel format to use for intermediate buffers.
        * On iOS GPU the supported values for this key are RGBA8 and RGBAh. If not specified RGBA8 us used.
        * On iOS CPU the only supported value for this key is RGBAf. If not specified RGBAf us used.
        * On OSX GPU the supported values for this key are RGBA8, RGBAh and RGBAf. If not specified RGBAh us used.
        * On OSX CPU the supported values for this key are RGBA8, RGBAh and RGBAf. If not specified RGBAh us used. */
        CORE_IMAGE_EXPORT NSString * const kCIContextWorkingFormat NS_AVAILABLE(10_4,8_0);


        Here's the log output when running the sample code, which arises when setting kCIFormatRGBAf as working format (both CPU and GPU contexts).
        CIContext workingformat must be kCIFormatBGRA8, kCIFormatRGBA8, kCIFormatRGBAh or nil. Ignoring request for RGBAf.
    email: raphael@creaceed.com
    modified: "2015-10-23T13:05:47.76643Z"
    number: "23234334"
    number_intvalue: 23234334
    originated: 23-Oct-2015 03:05 PM
    parent_number: '&{NULL_VALUE}'
    product: OS X SDK
    product_version: 10.11.1 (15B42)
    reproducible: Always
    resolved: ""
    status: Open
    title: Core Image on OS X does not allow RGBAf (32-bit floating-point) contexts anymore on El Capitan, leading to precision problems.
